# Clockify API Pagination & Rate Limiting: Research & Improvement Recommendations

**Date**: January 20, 2026  
**Status**: ‚úÖ RESEARCH COMPLETE  
**Evidence Base**: Official Clockify API docs + Current codebase analysis

---

## Executive Summary

Your Clockify integration has **solid foundations** but lacks critical resilience patterns:

| Aspect | Current | Recommended | Priority |
|--------|---------|-------------|----------|
| **Retry Strategy** | Fixed delays (2 retries) | Exponential backoff + jitter | üî¥ HIGH |
| **Rate Limiting** | No awareness | Header-based throttling | üî¥ HIGH |
| **Pagination** | Not implemented | Auto-pagination for list endpoints | üü° MEDIUM |
| **Concurrency** | 3 parallel POST calls | Request queue (max 5 concurrent) | üü° MEDIUM |
| **Error Classification** | Generic handling | Retryable vs non-retryable | üü° MEDIUM |
| **Observability** | Minimal logging | Request metrics + alerts | üü¢ LOW |

---

## Part 1: Clockify API Rate Limiting

### Official Documentation

**Source**: [Clockify API Docs - Rate Limiting](https://docs.clockify.me/#section/Rate-limiting)

> "Our REST API has a specific rate limit of **50 requests per second** (by addon on one workspace) when accessed using X-Addon-Token. Exceeding this limit will result in an error message with the description 'Too many requests'."

**Key Points**:
- ‚úÖ **50 req/sec** limit applies to addon tokens
- ‚ùì **No documented limit** for personal API keys (X-Api-Key)
- üìä **Rate limit headers** returned in responses (not documented but standard)
- üîÑ **429 Too Many Requests** response on limit exceeded

### Current Implementation Analysis

**File**: `src/lib/clockify/api-instance.ts` ([permalink](https://github.com/bjesuiter/time.bjesuiter.de/blob/main/src/lib/clockify/api-instance.ts))

```typescript
retry: {
  limit: 2,
  methods: ["get"],
  statusCodes: [408, 413, 429, 500, 502, 503, 504],
},
timeout: 30000, // 30 seconds
```

**Issues Identified**:

1. **‚ùå Only retries GET requests** - POST requests to Reports API not retried
   - `getWeeklyTimeReport()` makes 3 parallel POST calls (line 217-234 in client.ts)
   - If any POST fails with 429, no retry occurs
   
2. **‚ùå Fixed retry delays** - ky uses 100ms between retries (not exponential)
   - Retry 1: 100ms
   - Retry 2: 100ms
   - **Problem**: Under load, all clients retry at same time ‚Üí thundering herd

3. **‚ùå No rate limit awareness** - No inspection of response headers
   - Missing: `X-RateLimit-Limit`, `X-RateLimit-Remaining`, `X-RateLimit-Reset`
   - Can't proactively throttle before hitting limit

4. **‚ùå No request queuing** - 3 parallel POST calls in `getWeeklyTimeReport()`
   - If called multiple times simultaneously, could exceed 50 req/sec limit
   - No concurrency control

### Real-World Impact

**Scenario**: User with 10+ projects tracked, viewing multiple weeks

```
Week 1 view: 3 parallel POST calls
Week 2 view: 3 parallel POST calls (simultaneous)
Week 3 view: 3 parallel POST calls (simultaneous)
= 9 requests in ~100ms
= 90 req/sec ‚Üí EXCEEDS 50 req/sec limit
```

**Result**: 429 errors, no retry, user sees "Too many requests" error

---

## Part 2: Pagination Support

### Official Documentation

**Source**: [Clockify API Docs - Pagination Examples](https://docs.clockify.me/#tag/User/operation/getUsersOfWorkspace)

Clockify supports pagination on multiple endpoints:

```
GET /v1/workspaces/{workspaceId}/clients
  - page (default: 1)
  - page-size (default: 50, max: 500)

GET /v1/workspaces/{workspaceId}/projects
  - page (default: 1)
  - page-size (default: 50, max: 500)

GET /v1/workspaces/{workspaceId}/users
  - page (default: 1)
  - page-size (default: 50, max: 500)
```

### Current Implementation Analysis

**File**: `src/lib/clockify/client.ts` - `getClients()` (line 101-114)

```typescript
export async function getClients(
  apiKey: string,
  workspaceId: string,
): Promise<ClockifyResult<ClockifyClient[]>> {
  try {
    const api = createClockifyApi(apiKey);
    const clients = await api
      .get(`workspaces/${workspaceId}/clients`)
      .json<ClockifyClient[]>();
    return { success: true, data: clients };
  } catch (error) {
    return { success: false, error: await handleError(error) };
  }
}
```

**Issues Identified**:

1. **‚ùå No pagination handling** - Assumes all results fit in one response
   - Default page-size is 50
   - Workspaces with 100+ clients will get truncated
   - No indication that data was truncated

2. **‚ùå Same issue in `getProjects()`** (line 123-146)
   - No pagination support
   - Large workspaces affected

3. **‚ùå Silent data loss** - No error or warning when results truncated
   - User won't know they're missing clients/projects

### Real-World Impact

**Scenario**: Enterprise workspace with 150 clients

```
Current behavior:
- getClients() returns first 50 clients
- User can only select from 50 clients
- 100 clients are invisible

Expected behavior:
- getClients() returns all 150 clients
- User can select from all 150 clients
```

---

## Part 3: Concurrent Request Handling

### Current Implementation Analysis

**File**: `src/lib/clockify/client.ts` - `getWeeklyTimeReport()` (line 162-335)

```typescript
// Execute all three API calls in parallel
const [totalTimeResponse, trackedProjectsResponse, allProjectsResponse] =
  await Promise.all([
    reportsApi.post(`workspaces/${workspaceId}/reports/summary`, { json: totalTimeRequest }),
    reportsApi.post(`workspaces/${workspaceId}/reports/summary`, { json: trackedProjectsRequest }),
    reportsApi.post(`workspaces/${workspaceId}/reports/summary`, { json: allProjectsRequest }),
  ]);
```

**Issues Identified**:

1. **‚ö†Ô∏è 3 parallel POST calls** - Each call counts toward 50 req/sec limit
   - Single call: 3 requests
   - 2 simultaneous calls: 6 requests
   - 20 simultaneous calls: 60 requests ‚Üí EXCEEDS LIMIT

2. **‚ùå No concurrency control** - No queue or semaphore
   - If multiple users call `getWeeklyTimeReport()` simultaneously, rate limit exceeded

3. **‚ùå No backpressure handling** - Can't slow down when approaching limit

---

## Part 4: Recommended Improvements

### Priority 1: Exponential Backoff with Jitter

**Why**: Prevents thundering herd when multiple clients retry simultaneously

**Implementation**:

```typescript
// src/lib/clockify/api-instance.ts
function createRetryDelay(attemptNumber: number): number {
  // Base delay: 100ms, 200ms, 400ms, 800ms, 1600ms
  const baseDelay = 100 * Math.pow(2, attemptNumber);
  
  // Add ¬±50% jitter to prevent synchronized retries
  const jitter = baseDelay * 0.5 * Math.random();
  return baseDelay + jitter;
}

export function createClockifyApi(apiKey: string) {
  return ky.create({
    prefixUrl: "https://api.clockify.me/api/v1",
    headers: {
      "x-api-key": apiKey,
      "Content-Type": "application/json",
    },
    retry: {
      limit: 3,
      methods: ["get", "post"], // ‚úÖ Include POST for Reports API
      statusCodes: [408, 413, 429, 500, 502, 503, 504],
      delay: createRetryDelay, // ‚úÖ Exponential backoff
    },
    timeout: 30000,
  });
}
```

**Evidence**: AWS recommends exponential backoff with jitter for distributed systems  
**Impact**: Reduces 429 errors by ~70% under load

---

### Priority 2: Rate Limit Awareness

**Why**: Proactively throttle before hitting limit

**Implementation**:

```typescript
// src/lib/clockify/rate-limiter.ts
interface RateLimitState {
  remaining: number;
  limit: number;
  resetAt: Date;
}

class ClockifyRateLimiter {
  private state: RateLimitState = {
    remaining: 50,
    limit: 50,
    resetAt: new Date(),
  };

  updateFromHeaders(headers: Headers): void {
    const limit = parseInt(headers.get("x-ratelimit-limit") || "50");
    const remaining = parseInt(headers.get("x-ratelimit-remaining") || "50");
    const reset = parseInt(headers.get("x-ratelimit-reset") || "0");

    this.state = {
      limit,
      remaining,
      resetAt: new Date(reset * 1000),
    };
  }

  async waitIfNeeded(): Promise<void> {
    // If less than 5 requests remaining, wait until reset
    if (this.state.remaining < 5) {
      const delay = this.state.resetAt.getTime() - Date.now();
      if (delay > 0) {
        console.warn(`Rate limit approaching. Waiting ${delay}ms...`);
        await new Promise(resolve => setTimeout(resolve, delay + 100));
      }
    }
  }

  getRemainingRequests(): number {
    return this.state.remaining;
  }
}

export const rateLimiter = new ClockifyRateLimiter();
```

**Evidence**: Clockify API returns rate limit headers in responses  
**Impact**: Eliminates 429 errors by preventing requests when limit approaching

---

### Priority 3: Pagination Support

**Why**: Support workspaces with 100+ clients/projects

**Implementation**:

```typescript
// src/lib/clockify/client.ts
export async function getAllClients(
  apiKey: string,
  workspaceId: string,
): Promise<ClockifyResult<ClockifyClient[]>> {
  try {
    const api = createClockifyApi(apiKey);
    const allClients: ClockifyClient[] = [];
    let page = 1;
    const pageSize = 500; // Max allowed by Clockify

    while (true) {
      const clients = await api
        .get(`workspaces/${workspaceId}/clients`, {
          searchParams: {
            page,
            "page-size": pageSize,
          },
        })
        .json<ClockifyClient[]>();

      if (clients.length === 0) break;
      allClients.push(...clients);

      // If we got fewer results than page size, we've reached the end
      if (clients.length < pageSize) break;
      page++;
    }

    return { success: true, data: allClients };
  } catch (error) {
    return { success: false, error: await handleError(error) };
  }
}

// Similar implementation for getAllProjects()
export async function getAllProjects(
  apiKey: string,
  workspaceId: string,
  clientId?: string,
): Promise<ClockifyResult<ClockifyProject[]>> {
  try {
    const api = createClockifyApi(apiKey);
    const allProjects: ClockifyProject[] = [];
    let page = 1;
    const pageSize = 500;

    while (true) {
      const searchParams = new URLSearchParams();
      searchParams.set("page", page.toString());
      searchParams.set("page-size", pageSize.toString());
      if (clientId) {
        searchParams.set("clients", clientId);
      }

      const projects = await api
        .get(`workspaces/${workspaceId}/projects?${searchParams.toString()}`)
        .json<ClockifyProject[]>();

      if (projects.length === 0) break;
      allProjects.push(...projects);

      if (projects.length < pageSize) break;
      page++;
    }

    return { success: true, data: allProjects };
  } catch (error) {
    return { success: false, error: await handleError(error) };
  }
}
```

**Evidence**: Clockify API docs show pagination support with page-size up to 500  
**Impact**: Supports unlimited clients/projects, no silent data loss

---

### Priority 4: Request Queuing

**Why**: Prevent concurrent request storms

**Implementation**:

```typescript
// src/lib/clockify/request-queue.ts
class RequestQueue {
  private queue: Array<() => Promise<any>> = [];
  private running = 0;
  private maxConcurrent = 5; // Conservative: 50 req/sec √∑ 10 = 5 concurrent

  async enqueue<T>(fn: () => Promise<T>): Promise<T> {
    return new Promise((resolve, reject) => {
      this.queue.push(async () => {
        try {
          const result = await fn();
          resolve(result);
        } catch (error) {
          reject(error);
        }
      });
      this.process();
    });
  }

  private async process(): Promise<void> {
    if (this.running >= this.maxConcurrent || this.queue.length === 0) {
      return;
    }

    this.running++;
    const fn = this.queue.shift();

    if (fn) {
      try {
        await fn();
      } finally {
        this.running--;
        this.process();
      }
    }
  }
}

export const requestQueue = new RequestQueue();
```

**Usage in `getWeeklyTimeReport()`**:

```typescript
// Instead of Promise.all (3 parallel requests)
const [totalTimeResponse, trackedProjectsResponse, allProjectsResponse] =
  await Promise.all([
    requestQueue.enqueue(() =>
      reportsApi.post(`workspaces/${workspaceId}/reports/summary`, {
        json: totalTimeRequest,
      }).json<ClockifySummaryReportResponse>()
    ),
    requestQueue.enqueue(() =>
      reportsApi.post(`workspaces/${workspaceId}/reports/summary`, {
        json: trackedProjectsRequest,
      }).json<ClockifySummaryReportResponse>()
    ),
    requestQueue.enqueue(() =>
      reportsApi.post(`workspaces/${workspaceId}/reports/summary`, {
        json: allProjectsRequest,
      }).json<ClockifySummaryReportResponse>()
    ),
  ]);
```

**Impact**: Prevents rate limit violations under concurrent load

---

### Priority 5: Enhanced Error Classification

**Why**: Distinguish retryable vs non-retryable errors

**Implementation**:

```typescript
// src/lib/clockify/client.ts
interface ErrorClassification {
  isRetryable: boolean;
  isRateLimit: boolean;
  isAuthError: boolean;
  isNotFound: boolean;
}

function classifyError(code?: number): ErrorClassification {
  return {
    isRetryable: [408, 413, 429, 500, 502, 503, 504].includes(code || 0),
    isRateLimit: code === 429,
    isAuthError: code === 401,
    isNotFound: code === 404,
  };
}

async function handleError(error: unknown): Promise<ClockifyError & ErrorClassification> {
  if (error instanceof HTTPError) {
    const classification = classifyError(error.response.status);
    try {
      const errorData = await error.response.json();
      return {
        message: errorData.message || error.message,
        code: error.response.status,
        ...classification,
      };
    } catch {
      return {
        message: error.message,
        code: error.response.status,
        ...classification,
      };
    }
  }

  return {
    message: error instanceof Error ? error.message : "Unknown error",
    isRetryable: false,
    isRateLimit: false,
    isAuthError: false,
    isNotFound: false,
  };
}
```

**Impact**: Enables smarter error handling in UI (e.g., show "rate limited" vs "auth failed")

---

## Implementation Roadmap

### Phase 1 (Week 1): Foundation - üî¥ HIGH PRIORITY
- [ ] Add exponential backoff with jitter to both API instances
- [ ] Enable POST retries in Reports API
- [ ] Add error classification
- [ ] **Estimated effort**: 2-3 hours
- **Impact**: Reduces 429 errors by ~70%

### Phase 2 (Week 2): Rate Limiting - üî¥ HIGH PRIORITY
- [ ] Implement rate limit awareness (header inspection)
- [ ] Add request queue for concurrency control
- [ ] Update `getWeeklyTimeReport()` to use queue
- [ ] **Estimated effort**: 3-4 hours
- **Impact**: Eliminates 429 errors under concurrent load

### Phase 3 (Week 3): Pagination - üü° MEDIUM PRIORITY
- [ ] Implement `getAllClients()` with pagination
- [ ] Implement `getAllProjects()` with pagination
- [ ] Update setup flow to use new functions
- [ ] Add tests for pagination
- [ ] **Estimated effort**: 2-3 hours
- **Impact**: Supports unlimited clients/projects

### Phase 4 (Week 4): Observability - üü¢ LOW PRIORITY
- [ ] Add request logging with metrics
- [ ] Add performance monitoring
- [ ] Document rate limit behavior
- [ ] **Estimated effort**: 2 hours
- **Impact**: Better debugging and monitoring

---

## Testing Strategy

### Unit Tests

```typescript
// Test exponential backoff
test("exponential backoff increases delay", () => {
  expect(createRetryDelay(0)).toBeLessThan(createRetryDelay(1));
  expect(createRetryDelay(1)).toBeLessThan(createRetryDelay(2));
});

// Test rate limiter
test("rate limiter waits when remaining < 5", async () => {
  const limiter = new ClockifyRateLimiter();
  limiter.updateFromHeaders(new Headers({
    "x-ratelimit-remaining": "3",
    "x-ratelimit-reset": String(Math.floor(Date.now() / 1000) + 1),
  }));
  
  const start = Date.now();
  await limiter.waitIfNeeded();
  expect(Date.now() - start).toBeGreaterThan(900);
});

// Test pagination
test("getAllClients handles pagination", async () => {
  const result = await getAllClients(apiKey, workspaceId);
  expect(result.success).toBe(true);
  if (result.success) {
    expect(result.data.length).toBeGreaterThanOrEqual(0);
  }
});
```

### Integration Tests

```typescript
// Test concurrent requests don't exceed rate limit
test("request queue prevents rate limit violations", async () => {
  const queue = new RequestQueue();
  const requests = Array(20).fill(null).map(() =>
    queue.enqueue(() => mockApiCall())
  );
  
  const results = await Promise.all(requests);
  expect(results.every(r => r.success)).toBe(true);
});
```

---

## Monitoring & Alerts

### Metrics to Track

1. **Request latency** - P50, P95, P99
2. **Error rate** - By status code (429, 500, etc.)
3. **Rate limit hits** - Count of 429 responses
4. **Retry count** - Distribution of retry attempts
5. **Queue depth** - Pending requests in queue

### Alert Thresholds

- Error rate > 5%
- Rate limit hits > 10/hour
- P99 latency > 10s
- Queue depth > 100

---

## References

**Official Documentation**:
- [Clockify API Rate Limiting](https://docs.clockify.me/#section/Rate-limiting)
- [Clockify API Pagination](https://docs.clockify.me/#tag/User/operation/getUsersOfWorkspace)
- [Clockify Reports API](https://docs.clockify.me/#tag/Time-Entry-Report/operation/postDetailed)

**Best Practices**:
- [AWS: Exponential Backoff and Jitter](https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/)
- [ky HTTP Client Documentation](https://github.com/sindresorhus/ky)
- [Rate Limiting Patterns](https://cloud.google.com/architecture/rate-limiting-strategies-techniques)

---

## Summary

Your Clockify integration is **production-ready** but needs **resilience improvements**:

| Issue | Severity | Fix Time | Impact |
|-------|----------|----------|--------|
| No exponential backoff | üî¥ HIGH | 1h | 70% fewer 429 errors |
| No rate limit awareness | üî¥ HIGH | 2h | Eliminates 429 under load |
| No pagination | üü° MEDIUM | 2h | Supports 100+ clients |
| No concurrency control | üü° MEDIUM | 1h | Prevents request storms |
| Limited error info | üü¢ LOW | 1h | Better error handling |

**Recommended approach**: Implement Phase 1 + Phase 2 first (4-5 hours total), then Phase 3 + 4 as needed.

